{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "image_size=(300, 300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'H:\\\\IntensiveGitHub\\\\Intensive'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = pathlib.Path.cwd()\n",
    "dir_path = str(dir_path)\n",
    "dir_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1185 files belonging to 25 classes.\n",
      "Using 948 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory('All',\n",
    "                                             subset='training',\n",
    "                                             seed=42,\n",
    "                                             label_mode='categorical',\n",
    "                                             validation_split=0.2,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1185 files belonging to 25 classes.\n",
      "Using 237 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# generate\n",
    "validation_dataset = image_dataset_from_directory('All',\n",
    "                                                  subset='validation',\n",
    "                                                  label_mode='categorical',\n",
    "                                                  seed=42,\n",
    "                                                  validation_split=0.2,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['Baked_cheese_omelet',\n 'Bread_made_from_wheat_flour',\n 'Butter',\n 'Casserole',\n 'Cheese',\n 'Cheese_casserole',\n 'Cheese_sandwich',\n 'Cherry_Sauce',\n 'Coffee',\n 'Compote',\n 'Cookie',\n 'Fresh_seasonal_fruits',\n 'Juice',\n 'Kissel',\n 'Milk',\n 'Mix',\n 'Pasta_with_cheese',\n 'Pie_with_raisins',\n 'Porridge_with_milk',\n 'Rice porridge',\n 'Tea',\n 'TeaWithMilk',\n 'Water',\n 'buckwheat porridge',\n 'millet porridge']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.class_names\n",
    "class_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# test_dataset = image_dataset_from_directory('Training',\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# test_dataset.class_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 298, 298, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 149, 149, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 147, 147, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 73, 73, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 71, 71, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 35, 35, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 156800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               80282112  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                12825     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,391,129\n",
      "Trainable params: 80,389,657\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# # Создаем последовательную модель\n",
    "# model = Sequential()\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(16, (5, 5), padding='same',\n",
    "#                  input_shape=(300, 300, 3), activation='relu'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Полносвязная часть нейронной сети для классификации\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# # Выходной слой, 131 нейрон по количеству классов\n",
    "# model.add(Dense(25, activation='softmax'))\n",
    "# Модель\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "# компиляция модели многолассовой классификации\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, factor = 0.5, min_lr = 0.00001)\n",
    "callbacks = [early_stopping, reduce_lr]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    devices = sess.list_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs = 10,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks = callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(test_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Доля верных ответов на тестовых данных, в процентах:\", round(scores[1] * 100, 4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],\n",
    "         label='Доля верных ответов на обучающем наборе')\n",
    "plt.plot(history.history['val_accuracy'],\n",
    "         label='Доля верных ответов на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Доля верных ответов')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],\n",
    "         label='Ошибка на обучающем наборе')\n",
    "plt.plot(history.history['val_loss'],\n",
    "         label='Ошибка на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"fruits_360_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files.download(\"fruits_360_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
