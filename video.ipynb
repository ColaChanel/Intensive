{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "image_size=(300, 300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'H:\\\\IntensiveGitHub\\\\Intensive'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = pathlib.Path.cwd()\n",
    "dir_path = str(dir_path)\n",
    "dir_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1185 files belonging to 25 classes.\n",
      "Using 948 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory('All',\n",
    "                                             subset='training',\n",
    "                                             seed=42,\n",
    "                                             label_mode='categorical',\n",
    "                                             validation_split=0.2,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1185 files belonging to 25 classes.\n",
      "Using 237 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# generate\n",
    "validation_dataset = image_dataset_from_directory('All',\n",
    "                                                  subset='validation',\n",
    "                                                  label_mode='categorical',\n",
    "                                                  seed=42,\n",
    "                                                  validation_split=0.2,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['Baked_cheese_omelet',\n 'Bread_made_from_wheat_flour',\n 'Butter',\n 'Casserole',\n 'Cheese',\n 'Cheese_casserole',\n 'Cheese_sandwich',\n 'Cherry_Sauce',\n 'Coffee',\n 'Compote',\n 'Cookie',\n 'Fresh_seasonal_fruits',\n 'Juice',\n 'Kissel',\n 'Milk',\n 'Mix',\n 'Pasta_with_cheese',\n 'Pie_with_raisins',\n 'Porridge_with_milk',\n 'Rice porridge',\n 'Tea',\n 'TeaWithMilk',\n 'Water',\n 'buckwheat porridge',\n 'millet porridge']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.class_names\n",
    "class_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# test_dataset = image_dataset_from_directory('Training',\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             image_size=image_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# test_dataset.class_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 208s 2us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 62\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# # Создаем последовательную модель\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# model = Sequential()\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# # Сверточный слой\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# model.summary()\u001B[39;00m\n\u001B[0;32m     59\u001B[0m model \u001B[38;5;241m=\u001B[39m ResNet50()\n\u001B[1;32m---> 62\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m(Conv2D(\u001B[38;5;241m32\u001B[39m, (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m), activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m300\u001B[39m, \u001B[38;5;241m300\u001B[39m, \u001B[38;5;241m3\u001B[39m)))\n\u001B[0;32m     63\u001B[0m model\u001B[38;5;241m.\u001B[39madd(BatchNormalization())\n\u001B[0;32m     64\u001B[0m model\u001B[38;5;241m.\u001B[39madd(MaxPooling2D(pool_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m)))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Functional' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# # Создаем последовательную модель\n",
    "# model = Sequential()\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(16, (5, 5), padding='same',\n",
    "#                  input_shape=(300, 300, 3), activation='relu'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Сверточный слой\n",
    "# model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "# # Слой подвыборки\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Полносвязная часть нейронной сети для классификации\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# # Выходной слой, 131 нейрон по количеству классов\n",
    "# model.add(Dense(25, activation='softmax'))\n",
    "# Модель\n",
    "# model = Sequential()\n",
    "#\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "#\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "#\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "#\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(25, activation='softmax'))\n",
    "#\n",
    "# # компиляция модели многолассовой классификации\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#\n",
    "# model.summary()\n",
    "model = ResNet50()\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "# компиляция модели многолассовой классификации\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, factor = 0.5, min_lr = 0.00001)\n",
    "callbacks = [early_stopping, reduce_lr]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    devices = sess.list_devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs = 10,\n",
    "        validation_data = validation_dataset,\n",
    "        callbacks = callbacks\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Оцениваем качество обучения модели на тестовых данных\n",
    "scores = model.evaluate(test_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Доля верных ответов на тестовых данных, в процентах:\", round(scores[1] * 100, 4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],\n",
    "         label='Доля верных ответов на обучающем наборе')\n",
    "plt.plot(history.history['val_accuracy'],\n",
    "         label='Доля верных ответов на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Доля верных ответов')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],\n",
    "         label='Ошибка на обучающем наборе')\n",
    "plt.plot(history.history['val_loss'],\n",
    "         label='Ошибка на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"fruits_360_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files.download(\"fruits_360_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
